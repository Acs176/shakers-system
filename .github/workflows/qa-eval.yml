# Runs the QA evaluation manually and enforces thresholds
name: QA Evaluation

on:
  workflow_dispatch:
    inputs:
      kb_dir:
        description: Path to the knowledge base directory
        required: false
        default: kb
      dataset_path:
        description: Path to QA dataset JSON
        required: false
        default: kb/qa_test_dataset.json
      index_dir:
        description: Path to existing vector index directory
        required: false
        default: rag_index
      with_faithfulness:
        description: Compute RAGAS faithfulness (requires provider + API key)
        type: boolean
        required: false
        default: false
      provider:
        description: LLM provider for faithfulness (gemini|openai|none)
        required: false
        default: gemini
      oos_threshold:
        description: Out-of-scope score threshold [0-1]
        required: false
        default: '0.2'
      sim_model:
        description: SentenceTransformer model name for semantic similarity
        required: false
        default: sentence-transformers/all-mpnet-base-v2
      semantic_threshold:
        description: Minimum avg semantic similarity to pass
        required: false
        default: '0.7'
      faithfulness_threshold:
        description: Minimum avg faithfulness to pass (when enabled)
        required: false
        default: '0.8'
      retrieval_k:
        description: Top-k for retrieval evaluation
        required: false
        default: '5'
      retrieval_granularity:
        description: Relevance granularity for retrieval eval (doc|chunk)
        required: false
        default: doc
      retrieval_recall_threshold:
        description: Minimum avg recall@k to pass
        required: false
        default: '0.8'
      retrieval_mrr_threshold:
        description: Minimum avg MRR@k to pass
        required: false
        default: '0.7'
      retrieval_ndcg_threshold:
        description: Minimum avg nDCG@k to pass
        required: false
        default: '0.75'

  pull_request:
    types: [opened, synchronize, labeled, reopened]

jobs:
  qa-eval:
    # Manual via Actions tab, or labeled PR (label: qa-eval)
    if: >-
      ${{ github.event_name == 'workflow_dispatch' ||
          (github.event_name == 'pull_request' && contains(toJson(github.event.pull_request.labels), 'qa-eval')) }}
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: '1'
      # Inputs with fallbacks so PR runs get defaults
      KB_DIR: ${{ github.event.inputs.kb_dir || inputs.kb_dir || 'kb' }}
      DATASET_PATH: ${{ github.event.inputs.dataset_path || inputs.dataset_path || 'kb/qa_test_dataset.json' }}
      INDEX_DIR: ${{ github.event.inputs.index_dir || inputs.index_dir || 'rag_index' }}
      WITH_FAITHFULNESS: ${{ github.event.inputs.with_faithfulness || inputs.with_faithfulness || 'false' }}
      PROVIDER: ${{ github.event.inputs.provider || inputs.provider || 'gemini' }}
      OOS_THRESHOLD: ${{ github.event.inputs.oos_threshold || inputs.oos_threshold || '0.2' }}
      SIM_MODEL: ${{ github.event.inputs.sim_model || inputs.sim_model || 'sentence-transformers/all-mpnet-base-v2' }}
      SEMANTIC_THRESHOLD: ${{ github.event.inputs.semantic_threshold || inputs.semantic_threshold || '0.7' }}
      FAITHFULNESS_THRESHOLD: ${{ github.event.inputs.faithfulness_threshold || inputs.faithfulness_threshold || '0.8' }}
      RETRIEVAL_K: ${{ github.event.inputs.retrieval_k || inputs.retrieval_k || '5' }}
      GRANULARITY: ${{ github.event.inputs.retrieval_granularity || inputs.retrieval_granularity || 'doc' }}
      RETRIEVAL_RECALL_THRESHOLD: ${{ github.event.inputs.retrieval_recall_threshold || inputs.retrieval_recall_threshold || '0.8' }}
      RETRIEVAL_MRR_THRESHOLD: ${{ github.event.inputs.retrieval_mrr_threshold || inputs.retrieval_mrr_threshold || '0.7' }}
      RETRIEVAL_NDCG_THRESHOLD: ${{ github.event.inputs.retrieval_ndcg_threshold || inputs.retrieval_ndcg_threshold || '0.75' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify dataset exists
        shell: bash
        run: |
          ds="$DATASET_PATH"
          idx="$INDEX_DIR"
          echo "Dataset: $ds"; echo "Index dir: $idx"
          if [ ! -f "$ds" ]; then echo "Dataset not found: $ds"; exit 1; fi

      - name: Build vector index
        shell: bash
        run: |
          kb="$KB_DIR"
          idx="$INDEX_DIR"
          if [ -f "$idx/vectors.faiss" ] && [ -f "$idx/meta.json" ]; then
            echo "Index already present in $idx; skipping build."
          else
            if [ ! -d "$kb" ]; then
              echo "KB directory not found: $kb and no existing index in $idx."
              echo "Provide a valid kb_dir or prebuild the index at $idx."
              exit 1
            fi
            echo "Building index from $kb into $idx"
            python -m src.app.data_ingestor.build_index_script "$kb" "$idx"
          fi
          if [ ! -f "$idx/vectors.faiss" ] || [ ! -f "$idx/meta.json" ]; then
            echo "Failed to build vector index in $idx (expected vectors.faiss and meta.json)."; exit 1;
          fi

      - name: Resolve provider API key
        id: keys
        shell: bash
        run: |
          provider="${PROVIDER}"
          with_f="${WITH_FAITHFULNESS}"
          api_key=""
          case "$provider" in
            gemini)
              api_key="${{ secrets.GEMINI_API_KEY }}" ;;
            openai)
              api_key="${{ secrets.OPENAI_API_KEY }}" ;;
            none|"")
              provider="none" ;;
            *)
              echo "Unsupported provider: $provider"; exit 1 ;;
          esac
          if [ -z "$api_key" ]; then
            echo "Warning: No API key available for provider '$provider'. Will use extractive fallback if needed." >&2
            if [ "$with_f" = "true" ]; then
              echo "Warning: Faithfulness requested but no API key; metric may be skipped and threshold check may fail." >&2
            fi
          fi

          echo "provider=$provider" >> "$GITHUB_OUTPUT"
          echo "api_key=$api_key" >> "$GITHUB_OUTPUT"

      - name: Run QA evaluation
        shell: bash
        run: |
          ds="$DATASET_PATH"
          idx="$INDEX_DIR"
          oos="$OOS_THRESHOLD"
          sim="$SIM_MODEL"
          provider="${{ steps.keys.outputs.provider }}"
          api_key="${{ steps.keys.outputs.api_key }}"
          sem_thr="$SEMANTIC_THRESHOLD"
          faith_thr="$FAITHFULNESS_THRESHOLD"
          out="qa_eval_report.json"
          args=( -m src.eval.qa_eval --dataset "$ds" --index "$idx" --oos_threshold "$oos" --provider "${provider:-none}" --api_key "${api_key}" --out "$out" --sim_model "$sim" --semantic_min "$sem_thr" )
          if [ "${WITH_FAITHFULNESS}" = "true" ]; then args+=( --with_faithfulness --faithfulness_min "$faith_thr" ); fi
          echo "python ${args[*]}"
          python "${args[@]}"

      - name: Run Retrieval evaluation
        shell: bash
        run: |
          ds="$DATASET_PATH"
          idx="$INDEX_DIR"
          oos="$OOS_THRESHOLD"
          k="$RETRIEVAL_K"
          gran="$GRANULARITY"
          r_thr="$RETRIEVAL_RECALL_THRESHOLD"
          mrr_thr="$RETRIEVAL_MRR_THRESHOLD"
          ndcg_thr="$RETRIEVAL_NDCG_THRESHOLD"
          out="retrieval_eval_report.json"
          args=( -m src.eval.retrieval_eval --dataset "$ds" --index "$idx" --k "$k" --oos_threshold "$oos" --granularity "$gran" --out "$out" --recall_min "$r_thr" --mrr_min "$mrr_thr" --ndcg_min "$ndcg_thr" )
          echo "python ${args[*]}"
          python "${args[@]}"

      - name: Upload QA report
        uses: actions/upload-artifact@v4
        with:
          name: qa-eval-report
          path: qa_eval_report.json
      - name: Upload Retrieval report
        uses: actions/upload-artifact@v4
        with:
          name: retrieval-eval-report
          path: retrieval_eval_report.json
