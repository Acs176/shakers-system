# Runs the QA evaluation manually and enforces thresholds
name: QA Evaluation

on:
  workflow_dispatch:
    inputs:
      kb_dir:
        description: Path to the knowledge base directory
        required: false
        default: kb
      dataset_path:
        description: Path to QA dataset JSON
        required: false
        default: kb/qa_test_dataset.json
      index_dir:
        description: Path to existing vector index directory
        required: false
        default: rag_index
      with_faithfulness:
        description: Compute RAGAS faithfulness (requires provider + API key)
        type: boolean
        required: false
        default: false
      provider:
        description: LLM provider for faithfulness (gemini|openai|none)
        required: false
        default: none
      oos_threshold:
        description: Out-of-scope score threshold [0-1]
        required: false
        default: '0.2'
      sim_model:
        description: SentenceTransformer model name for semantic similarity
        required: false
        default: sentence-transformers/all-mpnet-base-v2
      semantic_threshold:
        description: Minimum avg semantic similarity to pass
        required: false
        default: '0.7'
      faithfulness_threshold:
        description: Minimum avg faithfulness to pass (when enabled)
        required: false
        default: '0.8'

  pull_request:
    types: [opened, synchronize, labeled, reopened]

jobs:
  qa-eval:
    # Manual via Actions tab, or labeled PR (label: qa-eval)
    if: >-
      ${{ github.event_name == 'workflow_dispatch' ||
          (github.event_name == 'pull_request' && contains(toJson(github.event.pull_request.labels), 'qa-eval')) }}
    runs-on: ubuntu-latest
    env:
      PYTHONUNBUFFERED: '1'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Verify dataset exists
        shell: bash
        run: |
          ds="${{ github.event.inputs.dataset_path }}"; [ -z "$ds" ] && ds="kb/qa_test_dataset.json"
          idx="${{ github.event.inputs.index_dir }}"; [ -z "$idx" ] && idx="rag_index"
          echo "Dataset: $ds"; echo "Index dir: $idx"
          if [ ! -f "$ds" ]; then echo "Dataset not found: $ds"; exit 1; fi

      - name: Build vector index
        shell: bash
        run: |
          kb="${{ github.event.inputs.kb_dir }}"; [ -z "$kb" ] && kb="kb"
          idx="${{ github.event.inputs.index_dir }}"; [ -z "$idx" ] && idx="rag_index"
          if [ -f "$idx/vectors.faiss" ] && [ -f "$idx/meta.json" ]; then
            echo "Index already present in $idx; skipping build."
          else
            if [ ! -d "$kb" ]; then
              echo "KB directory not found: $kb and no existing index in $idx."
              echo "Provide a valid kb_dir or prebuild the index at $idx."
              exit 1
            fi
            echo "Building index from $kb into $idx"
            python -m src.app.data_ingestor.build_index_script "$kb" "$idx"
          fi
          if [ ! -f "$idx/vectors.faiss" ] || [ ! -f "$idx/meta.json" ]; then
            echo "Failed to build vector index in $idx (expected vectors.faiss and meta.json)."; exit 1;
          fi

      - name: Resolve provider API key (for faithfulness)
        id: keys
        shell: bash
        run: |
          provider="${{ github.event.inputs.provider }}"
          with_f="${{ github.event.inputs.with_faithfulness }}"
          api_key=""
          if [ "$with_f" = "true" ]; then
            case "$provider" in
              gemini)
                api_key="${{ secrets.GEMINI_API_KEY }}" ;;
              openai)
                api_key="${{ secrets.OPENAI_API_KEY }}" ;;
              none|"")
                echo "with_faithfulness=true requires provider to be 'gemini' or 'openai'"; exit 1 ;;
              *)
                echo "Unsupported provider: $provider"; exit 1 ;;
            esac
            if [ -z "$api_key" ]; then echo "Missing API key secret for provider '$provider'"; exit 1; fi
          fi
          echo "provider=$provider" >> "$GITHUB_OUTPUT"
          echo "api_key=$api_key" >> "$GITHUB_OUTPUT"

      - name: Run QA evaluation
        shell: bash
        run: |
          ds="${{ github.event.inputs.dataset_path }}"; [ -z "$ds" ] && ds="kb/qa_test_dataset.json"
          idx="${{ github.event.inputs.index_dir }}"; [ -z "$idx" ] && idx="rag_index"
          oos="${{ github.event.inputs.oos_threshold }}"; [ -z "$oos" ] && oos="0.2"
          sim="${{ github.event.inputs.sim_model }}"; [ -z "$sim" ] && sim="sentence-transformers/all-mpnet-base-v2"
          provider="${{ steps.keys.outputs.provider }}"
          api_key="${{ steps.keys.outputs.api_key }}"
          sem_thr="${{ github.event.inputs.semantic_threshold }}"; [ -z "$sem_thr" ] && sem_thr="0.7"
          faith_thr="${{ github.event.inputs.faithfulness_threshold }}"; [ -z "$faith_thr" ] && faith_thr="0.8"
          out="qa_eval_report.json"
          args=( -m src.eval.qa_eval --dataset "$ds" --index "$idx" --oos_threshold "$oos" --provider "${provider:-none}" --api_key "${api_key}" --out "$out" --sim_model "$sim" --semantic_min "$sem_thr" )
          if [ "${{ github.event.inputs.with_faithfulness }}" = "true" ]; then args+=( --with_faithfulness --faithfulness_min "$faith_thr" ); fi
          echo "python ${args[*]}"
          python "${args[@]}"

      - name: Upload QA report
        uses: actions/upload-artifact@v4
        with:
          name: qa-eval-report
          path: qa_eval_report.json
